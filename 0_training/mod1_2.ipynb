{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7214611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "490e4271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='So you said you were researching ocean mammals?', additional_kwargs={}, response_metadata={}, name='Model', tool_calls=[], invalid_tool_calls=[])\n",
      "HumanMessage(content=\"Yes, that's right.\", additional_kwargs={}, response_metadata={}, name='Lance')\n",
      "AIMessage(content='Great, what would you like to learn about.', additional_kwargs={}, response_metadata={}, name='Model', tool_calls=[], invalid_tool_calls=[])\n",
      "HumanMessage(content='I want to learn about the best place to see Orcas in the US.', additional_kwargs={}, response_metadata={}, name='Lance')\n"
     ]
    }
   ],
   "source": [
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    pprint(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model='gpt-5-nano-2025-08-07')\n",
    "ouput_llm=llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67685e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice question, Lance. The two best U.S. destinations to reliably see orcas are:\n",
      "\n",
      "- Puget Sound / San Juan Islands, Washington\n",
      "  - Why: Classic, close-to-shore viewing of resident and transient killer whales. Lots of laid‑back vantage points from land, plus numerous licensed whale-watching tours.\n",
      "  - When: Late spring through fall (roughly May–September), with summer often giving the most sightings.\n",
      "  - What to expect: Smaller pods, frequent surface breaks, and plenty of other wildlife. It’s also where many SRKW (Southern Resident) sightings occur, though they’re endangered and viewing rules apply to protect them.\n",
      "\n",
      "- Southeast Alaska (Inside Passage: Juneau, Sitka, Ketchikan, Petersburg, etc.)\n",
      "  - Why: Vast wilderness, high whale density, and both resident and transient orcas, plus other wildlife like whales, eagles, bears.\n",
      "  - When: Mostly the summer to early fall window (May–September) is best for reliable sightings and long daylight.\n",
      "  - What to expect: Bigger, more rugged scenery; seeing larger groups and a mix of pod types is common on Alaska cruises or local wildlife tours.\n",
      "\n",
      "Tips for planning\n",
      "- Choose licensed operators and follow local guidelines to minimize disturbance (distance, speed, and approach rules are in place).\n",
      "- If you want the closest experience with resident pods, Puget Sound’s San Juan Islands is the classic pick.\n",
      "- If you’re after dramatic scenery and more diverse whale activity, Alaska is unbeatable, especially on a multi-day wildlife cruise or a Gulf of Alaska trip.\n",
      "- Consider combining a land-based stay (like Friday Harbor or Juneau) with a day or two of boat-based tours.\n",
      "\n",
      "Would you like a quick, sample 1-2 week plan for Washington state vs. Alaska, or help narrowing down based on your travel window and budget?\n"
     ]
    }
   ],
   "source": [
    "ouput_llm.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb54eab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 70,\n",
       " 'output_tokens': 2757,\n",
       " 'total_tokens': 2827,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 2368}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ouput_llm.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e75726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a : int , b: int) -> int : \n",
    "    \"\"\"Multiply a by b \n",
    "\n",
    "    Args:\n",
    "        a (int): first int \n",
    "        b (int): second int \n",
    "\n",
    "    Returns:\n",
    "        int: _description_\n",
    "    \"\"\"\n",
    "    return a*b \n",
    "\n",
    "llm_with_tools= llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "023a4504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "output_llm_tools= llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\")])\n",
    "output_llm_tools.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_core.messages import AnyMessage # a list of messages with a prebuild add_messages reducer\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Option 1: \n",
    "class MessageState(TypedDict): \n",
    "    messages: Annotated[list[AnyMessage],  add_messages ]\n",
    "    \n",
    "# Option 2: \n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessageState): \n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c99569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "x-with-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
